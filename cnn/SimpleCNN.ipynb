{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))  # CIFAR-100均值和標準差\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=512, shuffle=False)\n"
      ],
      "metadata": {
        "id": "m5yxyh-OyQJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "print(\"訓練圖像:\")\n",
        "imshow(torchvision.utils.make_grid(images[:8]))\n",
        "print('標籤:', labels[:8].numpy())\n",
        "\n",
        "dataiter = iter(test_loader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "print(\"測試圖像:\")\n",
        "imshow(torchvision.utils.make_grid(images[:8]))\n",
        "print('標籤:', labels[:8].numpy())\n"
      ],
      "metadata": {
        "id": "KN5EitbbyXxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128 * 16 * 16, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 100)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = SimpleCNN().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "w2KYq9-v43n1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "training_losses = []\n",
        "testing_losses = []\n",
        "training_accuracies = []\n",
        "testing_accuracies = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # Training phase\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Calculate training accuracy\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total_train += labels.size(0)\n",
        "        correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "    avg_training_loss = running_loss / len(train_loader)\n",
        "    training_losses.append(avg_training_loss)\n",
        "    training_accuracy = 100 * correct_train / total_train\n",
        "    training_accuracies.append(training_accuracy)\n",
        "    print(f'Epoch [{epoch+1}/{epochs}], Training Loss: {avg_training_loss:.4f}, Training Accuracy: {training_accuracy:.2f}%')\n",
        "\n",
        "    # Testing phase\n",
        "    model.eval()\n",
        "    testing_loss = 0.0\n",
        "    correct_test = 0\n",
        "    total_test = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            testing_loss += loss.item()\n",
        "\n",
        "            # Calculate testing accuracy\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total_test += labels.size(0)\n",
        "            correct_test += (predicted == labels).sum().item()\n",
        "\n",
        "    avg_testing_loss = testing_loss / len(test_loader)\n",
        "    testing_losses.append(avg_testing_loss)\n",
        "    testing_accuracy = 100 * correct_test / total_test\n",
        "    testing_accuracies.append(testing_accuracy)\n",
        "    print(f'Epoch [{epoch+1}/{epochs}], Testing Loss: {avg_testing_loss:.4f}, Testing Accuracy: {testing_accuracy:.2f}%')"
      ],
      "metadata": {
        "id": "-sJ4fdzHytXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Final Accuracy\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy on CIFAR-100: {100 * correct / total:.2f}%')\n",
        "\n",
        "# Plot losses and accuracies\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot Training and Testing Losses\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(1, epochs + 1), training_losses, label='Training Loss')\n",
        "plt.plot(range(1, epochs + 1), testing_losses, label='Testing Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Training and Testing Loss')\n",
        "\n",
        "# Plot Training and Testing Accuracies\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(1, epochs + 1), training_accuracies, label='Training Accuracy')\n",
        "plt.plot(range(1, epochs + 1), testing_accuracies, label='Testing Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.legend()\n",
        "plt.title('Training and Testing Accuracy')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Nm-RD6GB8j6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "mean = np.array([0.5, 0.5, 0.5])\n",
        "std = np.array([0.5, 0.5, 0.5])\n",
        "\n",
        "model.eval()\n",
        "num_images = 30\n",
        "images_shown = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        if images_shown >= num_images:\n",
        "            break\n",
        "\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        for i in range(images.size(0)):\n",
        "            if images_shown < num_images:\n",
        "                image = images[i].cpu().numpy().transpose((1, 2, 0))\n",
        "                image = image * std + mean\n",
        "                image = np.clip(image, 0, 1)\n",
        "\n",
        "                plt.subplot(5, 6, images_shown + 1)\n",
        "                plt.imshow(image)\n",
        "                plt.axis('off')\n",
        "\n",
        "                true_class = labels[i].item()\n",
        "                predicted_class = predicted[i].item()\n",
        "                plt.title(f'True: {true_class}, Pred: {predicted_class}', fontsize=8)\n",
        "\n",
        "                images_shown += 1\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "yGKBByd38yHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'model_weights.pth')"
      ],
      "metadata": {
        "id": "brIKrZmJGPu-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}